# Lexer
Made By Felipe G
# Overview
The lexer analyzer program is designed to tokenize text files into meaningful units called tokens. Tokens represent different elements of the source  such as identifiers, keywords, operators, separators, integers, and real numbers.
# Features
-Tokenize text files based on predefined rules\
-Writes and reads text files\
-No command line required\
# How to use
-Program reads and writes to predefined files that can be found in the code and utilities folder\
-Write the desire string or code in "input_code.txt"\
-Run debug\
-The tokenization if successful will be available on "output.txt"
# Token types
The lexer recognizes the following token types:

**Identifier:** Names used for variables, functions, etc.\
**Keyword:** Reserved words with special meaning in the programming language.\
**Operator:** Symbols used for mathematical, logical, and assignment operations.\
**Separator:** Symbols used to separate different elements of code.\
**Integer:** Whole numbers.\
**Real Number: **Numbers with decimal points.
